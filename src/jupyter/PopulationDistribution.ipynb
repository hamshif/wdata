{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "!{sys.executable} -m pip install -e '../../../Wielder/'\n",
    "!{sys.executable} -m pip install -e '../'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# POC of how to install and uninstall local packages\n",
    "\n",
    "# !{sys.executable} -m pip install -e '../../../pep-services/src/'\n",
    "# !{sys.executable} -m pip uninstall wield-services -y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from wielder.util.hocon_util import resolve_ordered\n",
    "\n",
    "project_conf = '../conf/project.conf'\n",
    "\n",
    "ordered_project_files = [project_conf]\n",
    "\n",
    "conf = resolve_ordered(\n",
    "    ordered_conf_paths=ordered_project_files)\n",
    "\n",
    "print(conf)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cddf69e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bee Hive data https://drive.google.com/file/d/142IBcs6OyQiJxO7owPfkEBFbkrudnh0g/view?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3ac867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3b810d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and start Spark session\n",
    "spark = SparkSession.builder.appName(\"BeeHive\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5811e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create schema for the data\n",
    "\n",
    "# All column names\n",
    "headers = conf['population']['cols_name']\n",
    "\n",
    "# All column names that their values are doubles\n",
    "cols_double = conf['population']['cols_double']\n",
    "\n",
    "# All column names that their values are integers\n",
    "cols_integer = conf['population']['cols_integer']\n",
    "\n",
    "def struct_field(header, doubles, integers):\n",
    "    \n",
    "    # Create a field for double type column\n",
    "    if header in doubles:\n",
    "        return StructField(header, DoubleType())\n",
    "    \n",
    "    # Create a field for integer type column\n",
    "    if header in integers:\n",
    "        return StructField(header, IntegerType())\n",
    "    \n",
    "    # # Create a field for string type column\n",
    "    return StructField(header, StringType())\n",
    "\n",
    "# Create all the fields\n",
    "fields = [struct_field(header, cols_double, cols_integer) for header in headers]\n",
    "\n",
    "# Create the schema from th e fields\n",
    "schema = StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26af61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the csv using the schema\n",
    "df = spark.read.schema(schema).csv('BeeHiveTestData.csv')\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765325df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns with the string remove in them\n",
    "cols_to_keep = [x for x in df.columns if 'remove' not in x]\n",
    "df = df.select(*cols_to_keep)\n",
    "\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns\n",
    "cols_to_drop = ('DaughtersEfficiencyScore', 'Father TYPE', 'X', 'Y', 'Z')\n",
    "df_cleaned = df.drop(*cols_to_drop)\n",
    "\n",
    "df_cleaned.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf9f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of bees for each Father SIZE\n",
    "df_cleaned = df_cleaned.groupBy('Father SIZE').count()\n",
    "\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecc0629",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e04b4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from pyspark data frame to numpy array\n",
    "df_cleaned_np = np.array(df_cleaned.select('Father SIZE', 'count').collect())\n",
    "\n",
    "df_cleaned_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599a902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bar chart based on amount of bees in each Father SIZE group\n",
    "\n",
    "# Create plot figure and axes\n",
    "fig, ax = plt.subplots(figsize =(8, 7))\n",
    "\n",
    "# Create bars and their labels\n",
    "ax.bar([str(i) for i in df_cleaned_np[:,0]], df_cleaned_np[:,1])\n",
    "\n",
    "# Add x, y gridlines\n",
    "ax.grid( color ='grey', linestyle ='-.', linewidth = 0.5, alpha = 0.2)\n",
    "\n",
    "for bar in ax.patches:\n",
    "   \n",
    "  # Using Matplotlib's annotate function and\n",
    "  # passing the coordinates where the annotation shall be done\n",
    "  # x-coordinate: bar.get_x() + bar.get_width() / 2\n",
    "  # y-coordinate: bar.get_height()\n",
    "  # free space to be left to make graph pleasing: (0, 8)\n",
    "  # ha and va stand for the horizontal and vertical alignment\n",
    "    ax.annotate(format(bar.get_height(), '.0f'),\n",
    "                   (bar.get_x() + bar.get_width() / 2,\n",
    "                    bar.get_height()), ha='center', va='center',\n",
    "                   size=15, xytext=(0, 8),\n",
    "                   textcoords='offset points')\n",
    "    \n",
    "\n",
    "# Add Plot Title\n",
    "ax.set_title('Bee population distribution by father size', fontsize = 25)\n",
    "\n",
    "# Set x axis name\n",
    "ax.set_xlabel(\"Father size\", fontsize =18)\n",
    "\n",
    "# Set y axis name\n",
    "ax.set_ylabel('Bees amout', fontsize =18)\n",
    "\n",
    "# Show plot, not necessary but used to remove unwanted output\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916b9e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create horizonatal bar chart based on amount of bees in each Father SIZE group\n",
    "\n",
    "# Create plot figure and axes\n",
    "fig, ax = plt.subplots(figsize =(9, 8))\n",
    " \n",
    "# # Create horizontal bars and their labels\n",
    "ax.barh([str(i) for i in df_cleaned_np[:,0]], df_cleaned_np[:,1])\n",
    " \n",
    "# Add x, y gridlines\n",
    "ax.grid( color ='grey', linestyle ='-.', linewidth = 0.5, alpha = 0.2)\n",
    " \n",
    "# Add annotation to bars\n",
    "for i in ax.patches:\n",
    "    plt.text(i.get_width()+0.2, i.get_y()+0.5,\n",
    "             str(round((i.get_width()), 2)),\n",
    "             fontsize = 10, fontweight ='bold',\n",
    "             color ='grey')\n",
    "    \n",
    "# Add Plot Title\n",
    "ax.set_title('Bee population distribution by father size', fontsize = 25)\n",
    "\n",
    "# Set x axis name\n",
    "ax.set_xlabel('Bees amout', fontsize =18)\n",
    "\n",
    "# Set y axis name\n",
    "ax.set_ylabel('Father size', fontsize =18)\n",
    "\n",
    "# Show plot, not necessary but used to remove unwanted output\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pie chart based on amount of bees (in %) in each Father SIZE group\n",
    "\n",
    "# Create plot figure and axes\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "# Create pie slices (in %) and their labels\n",
    "ax1.pie(df_cleaned_np[:,1], labels=df_cleaned_np[:,0], autopct='%1.2f%%')\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.axis('equal')  \n",
    "\n",
    "# Show plot, not necessary but used to remove unwanted output\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
