{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bee Hive data https://drive.google.com/file/d/142IBcs6OyQiJxO7owPfkEBFbkrudnh0g/view?usp=sharing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "APP = 'BeeHive'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "!{sys.executable} -m pip install -e '../../../Wielder/'\n",
    "!{sys.executable} -m pip install -e '../'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, IntegerType\n",
    "from pyspark.sql.functions import split, row_number, udf, col\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pep_data.project import get_project_conf\n",
    "from pep_data.spark.util import field_to_struct\n",
    "\n",
    "import random\n",
    "#from treelib import Node, Tree\n",
    "from treelib import Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(APP).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get app configuration from project.conf file\n",
    "conf = get_project_conf()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schema for the data\n",
    "cols_name = conf[APP]['cols_name']\n",
    "cols_double = conf[APP]['cols_double']\n",
    "cols_integer = conf[APP]['cols_integer']\n",
    "\n",
    "# Create all the fields\n",
    "fields = [field_to_struct(header, doubles=cols_double, integers=cols_integer) for header in cols_name]\n",
    "\n",
    "# Create the schema from th e fields\n",
    "schema = StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ff885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the csv using the schema\n",
    "data_path = conf[APP]['data_path']\n",
    "df = spark.read.schema(schema).csv(data_path)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f950c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns(the columns with the word remove in them)\n",
    "cols_to_keep = [x for x in df.columns if 'remove' not in x]\n",
    "df = df.select(*cols_to_keep)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Bee_ID column to Cycle(Bee value) and Cycle ID(ID value) columns\n",
    "df_cleaned = df.withColumn('Cycle', split(col('Bee ID'), '_')\\\n",
    "                           .getItem(0))\\\n",
    "               .withColumn('Cycle ID', split(col('Bee ID'), '_')\\\n",
    "                           .getItem(1))\n",
    "\n",
    "# Change the type of value in Cycle column from string to integer\n",
    "df_cleaned= df_cleaned.withColumn(\"Cycle\",col(\"Cycle\")\\\n",
    "                                  .cast(IntegerType()))\n",
    "\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9598022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data frame by Cycle column and add row number for each row(new column with the name Continuous ID)\n",
    "w = Window().orderBy('Cycle')\n",
    "df_cleaned = df_cleaned.withColumn('Continuous ID', row_number()\\\n",
    "                                   .over(w))\n",
    "\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b390d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with key = cycle , value = minimum value of Continuous ID of cycle(key)\n",
    "continuous_min_id_per_cycle = {key : value for key, value  in df_cleaned.groupBy('Cycle').min('Continuous ID').collect()}\n",
    "\n",
    "continuous_min_id_per_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5502f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sorted list of all distinct values of Cycle column\n",
    "cycles = sorted([i[0] for i in df_cleaned.select('Cycle').distinct().collect()])\n",
    "\n",
    "cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return parent continuous id according to cycle and n\n",
    "def assert_parent_bee_id(cycle):\n",
    "    n = 3\n",
    "\n",
    "    # Get index  of cycle in cycles list\n",
    "    cycle_index = cycles.index(cycle)\n",
    "\n",
    "    # Return parent bee id if cycle is 0\n",
    "    if  not cycle_index :\n",
    "        return None\n",
    "\n",
    "    min_cycle_index = 0\n",
    "\n",
    "    # Update min_cycle_index according to cycle_index and n\n",
    "    if cycle_index > n:\n",
    "        min_cycle_index = cycle_index - n\n",
    "\n",
    "    # Calculate the minimum value for random parent continuous id\n",
    "    min_rand_value = continuous_min_id_per_cycle[cycles[min_cycle_index]]\n",
    "\n",
    "    # Calculate the maximum value for random parent continuous id\n",
    "    max_rand_vale = continuous_min_id_per_cycle[cycles[cycle_index]] - 1\n",
    "\n",
    "    # Get random value of parent_continuous_id (from min_rand_value to max_rand_vale)\n",
    "    parent_continuous_id = random.randint(min_rand_value, max_rand_vale)\n",
    "\n",
    "    return parent_continuous_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23946054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert assert_parent_bee_id(cycle) to user defined function\n",
    "assert_parent_bee_id_udf = udf(lambda z: assert_parent_bee_id(z))\n",
    "\n",
    "# Create new column Parent Continuous ID using the assert_parent_bee_id_udf function and Cycle column\n",
    "# cache() caches the specified data frame in the memory of your cluster's workers\n",
    "# If executing multiple actions on the same data frame then cache it\n",
    "df_cleaned = df_cleaned.withColumn(\"Parent Continuous ID\", assert_parent_bee_id_udf(col('Cycle')))\\\n",
    "                        .cache()\n",
    "\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a tree using the idea of bfs algorithm\n",
    "\n",
    "# Get the root parent (first node of the tree)\n",
    "root_parent_continuous_id = 1\n",
    "root_parent = df_cleaned.filter(df_cleaned['Continuous ID'] == root_parent_continuous_id).collect()[0]\n",
    "\n",
    "# list of rows from df_cleand that will be nodes in the tree\n",
    "tree_nodes = [root_parent]\n",
    "\n",
    "# Create tree\n",
    "tree = Tree()\n",
    "\n",
    "# Add first node(root) to tree\n",
    "tree.create_node(root_parent['Bee ID'], root_parent['Bee ID'])\n",
    "\n",
    "# While tree_nodes not empty pop first value (parent) search for its kids append them to tree_nodes and add them to the tree\n",
    "while tree_nodes:\n",
    "    # Get first value in tree_nodes\n",
    "    parent = tree_nodes.pop()\n",
    "\n",
    "    #find all rows in df_cleaned which their value in Parent Continuous ID column equals parent's Continuous ID\n",
    "    kids = df_cleaned.filter(col('Parent Continuous ID') == parent['Continuous ID'])\n",
    "\n",
    "    # for each kid in kids append to tree_nodes and add it to tree\n",
    "    for k in kids.collect():\n",
    "        tree_nodes.append(k)\n",
    "        tree.create_node(k['Bee ID'], k['Bee ID'], parent['Bee ID'] )\n",
    "\n",
    "\n",
    "tree.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
