{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Bee Hive data https://drive.google.com/file/d/142IBcs6OyQiJxO7owPfkEBFbkrudnh0g/view?usp=sharing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "APP = 'BeeHive'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "!{sys.executable} -m pip install -e '../../../Wielder/'\n",
    "#!{sys.executable} -m pip install -e '../'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, IntegerType, StringType\n",
    "from pyspark.sql.functions import split, row_number, udf, col, min\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "from pep_data.project import quick_conf\n",
    "from pep_data.spark.util import field_to_struct\n",
    "\n",
    "import random\n",
    "#from treelib import Node, Tree\n",
    "from treelib import Tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1809e37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Spark session\n",
    "spark = SparkSession.builder.appName(APP).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get app configuration from project.conf file\n",
    "conf = quick_conf()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60e1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create schema for the data\n",
    "cols_name = conf[APP]['cols_name']\n",
    "cols_double = conf[APP]['cols_double']\n",
    "cols_integer = conf[APP]['cols_integer']\n",
    "\n",
    "# Create all the fields\n",
    "fields = [field_to_struct(header, doubles=cols_double, integers=cols_integer) for header in cols_name]\n",
    "\n",
    "# Create the schema from th e fields\n",
    "schema = StructType(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26ff885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from the csv using the schema\n",
    "data_path = conf[APP]['data_path']\n",
    "df = spark.read.schema(schema).csv(data_path)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f950c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecessary columns(the columns with the word remove in them)\n",
    "cols_to_keep = [x for x in df.columns if 'remove' not in x]\n",
    "df = df.select(*cols_to_keep)\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248b2a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Bee_ID column to Cycle(Bee value) and Cycle ID(ID value) columns\n",
    "df_cleaned = df.withColumn('Cycle', split(col('Bee ID'), '_')\\\n",
    "                           .getItem(0))\\\n",
    "               .withColumn('Cycle ID', split(col('Bee ID'), '_')\\\n",
    "                           .getItem(1))\n",
    "\n",
    "# Change the type of value in Cycle column from string to integer\n",
    "df_cleaned= df_cleaned.withColumn(\"Cycle\",col(\"Cycle\")\\\n",
    "                                  .cast(IntegerType()))\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9598022",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data frame by Cycle column and add row number for each row(new column with the name Continuous ID)\n",
    "w = Window().orderBy('Cycle')\n",
    "df_cleaned = df_cleaned.withColumn('Continuous ID', row_number()\\\n",
    "                                   .over(w))\n",
    "\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b390d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary with key = cycle , value = minimum value of Continuous ID of cycle(key)\n",
    "continuous_min_id_per_cycle = {key : value for key, value  in df_cleaned.groupBy('Cycle').min('Continuous ID').collect()}\n",
    "\n",
    "continuous_min_id_per_cycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5502f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sorted list of all distinct values of Cycle column\n",
    "cycles = sorted([i[0] for i in df_cleaned.select('Cycle').distinct().collect()])\n",
    "\n",
    "cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80aa79ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return parent continuous id according to cycle and n\n",
    "def assert_parent_bee_id(cycle):\n",
    "    n = 3\n",
    "\n",
    "    # Get index  of cycle in cycles list\n",
    "    cycle_index = cycles.index(cycle)\n",
    "\n",
    "    # Return parent bee id if cycle is 0\n",
    "    if  not cycle_index :\n",
    "        return None\n",
    "\n",
    "    min_cycle_index = 0\n",
    "\n",
    "    # Update min_cycle_index according to cycle_index and n\n",
    "    if cycle_index > n:\n",
    "        min_cycle_index = cycle_index - n\n",
    "\n",
    "    # Calculate the minimum value for random parent continuous id\n",
    "    min_rand_value = continuous_min_id_per_cycle[cycles[min_cycle_index]]\n",
    "\n",
    "    # Calculate the maximum value for random parent continuous id\n",
    "    max_rand_vale = continuous_min_id_per_cycle[cycles[cycle_index]] - 1\n",
    "\n",
    "    # Get random value of parent_continuous_id (from min_rand_value to max_rand_vale)\n",
    "    parent_continuous_id = random.randint(min_rand_value, max_rand_vale)\n",
    "\n",
    "    return parent_continuous_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23946054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert assert_parent_bee_id(cycle) to user defined function\n",
    "assert_parent_bee_id_udf = udf(lambda z: assert_parent_bee_id(z))\n",
    "\n",
    "# Create new column Parent Continuous ID using the assert_parent_bee_id_udf function and Cycle column\n",
    "# cache() caches the specified data frame in the memory of your cluster's workers\n",
    "# If executing multiple actions on the same data frame then cache it\n",
    "df_cleaned = df_cleaned.withColumn(\"Parent Continuous ID\", assert_parent_bee_id_udf(col('Cycle')))\\\n",
    "                        .cache()\n",
    "\n",
    "df_cleaned.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create forest start"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a DataFrame of parent bees\n",
    "df_parent_bees = df_cleaned.select('Bee ID', 'Continuous ID')\n",
    "df_parent_bees = df_parent_bees.withColumnRenamed(\"Bee ID\",\"Parent Bee ID\")\n",
    "df_parent_bees = df_parent_bees.withColumnRenamed(\"Continuous ID\",\"Temp Continuous ID\")\n",
    "df_parent_bees= df_parent_bees.withColumn(\"Temp Continuous ID\",col(\"Temp Continuous ID\")\\\n",
    "                                  .cast(StringType()))\n",
    "\n",
    "df_parent_bees.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add the parent bee id to each bee id with the use of join\n",
    "df_beeId_parent_beeId= df_cleaned.join(df_parent_bees, df_cleaned['Parent Continuous ID'] == df_parent_bees['Temp Continuous ID'],'left')\n",
    "df_beeId_parent_beeId.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a forest\n",
    "def create_tree():\n",
    "    tree =Tree()\n",
    "    tree.create_node('God', 'God')\n",
    "\n",
    "    # Add all the bees for cycle 0 to god\n",
    "    df_cleaned_0_cycle = df_beeId_parent_beeId.filter(col('Cycle') == 0)\n",
    "    for row in df_cleaned_0_cycle.collect():\n",
    "        tree.create_node(str(row['Bee ID']), str(row['Bee ID'])+'-'+str(row['Continuous ID']), 'God')\n",
    "    # get all bees in cycle c\n",
    "    for c in cycles[1:]:\n",
    "        df_cleaned_c_cycle = df_beeId_parent_beeId.filter(col('Cycle') == c)\n",
    "        # Add bee from cycle c to tree\n",
    "        for row in df_cleaned_c_cycle.collect():\n",
    "            tree.create_node(str(row['Bee ID']), str(row['Bee ID'])+'-'+str(row['Continuous ID']), str(row['Parent Bee ID'])+'-'+str(row['Parent Continuous ID']) )\n",
    "\n",
    "    return tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree = create_tree()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_name = 'forest.txt'\n",
    "tree.save2file(conf[APP]['data_save']+file_name)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create forest end"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Choose bee roots for the tree\n",
    "bee_ancestor_continuous_id = 1\n",
    "bee_ancestors = df_cleaned.filter(df_cleaned['Continuous ID'] <= bee_ancestor_continuous_id).collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a tree using the idea of bfs algorithm\n",
    "# Slow version for alot of nodes\n",
    "# Works fast for a subtree (only one or few bees as roots)\n",
    "def create_tree_bfs(tree_nodes):\n",
    "    tree = Tree()\n",
    "\n",
    "    # Add first node/s(root/s) to tree\n",
    "    if len(tree_nodes) == 1:\n",
    "        tree.create_node(str(tree_nodes[0]['Bee ID']), str(tree_nodes[0]['Bee ID'])+'-'+str(tree_nodes[0]['Continuous ID']))\n",
    "\n",
    "    else:\n",
    "        tree.create_node('God', 'God')\n",
    "        for root in tree_nodes:\n",
    "            tree.create_node(str(root['Bee ID']), str(root['Bee ID'])+'-'+str(root['Continuous ID']), 'God')\n",
    "\n",
    "    # While tree_nodes not empty pop first value (parent) search for its kids append them to tree_nodes and add them to the tree\n",
    "    while tree_nodes:\n",
    "        # Get first value in tree_nodes\n",
    "        parent = tree_nodes.pop()\n",
    "\n",
    "        #find all rows in df_cleaned which their value in Parent Continuous ID column equals parent's Continuous ID\n",
    "        kids = df_cleaned.filter(col('Parent Continuous ID') == parent['Continuous ID'])\n",
    "\n",
    "        # for each kid in kids append to tree_nodes and add it to tree\n",
    "        for k in kids.collect():\n",
    "                tree_nodes.append(k)\n",
    "                tree.create_node(str(k['Bee ID']), str(k['Bee ID'])+'-'+str(k['Continuous ID']), str(parent['Bee ID'])+'-'+str(parent['Continuous ID']) )\n",
    "\n",
    "    return tree"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create tree\n",
    "tree = create_tree_bfs(bee_ancestors)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "tree.size()\n",
    "tree.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a DataFrame with the best bee per cycle\n",
    "w = Window.partitionBy('Cycle')\n",
    "df_best_bee = df_cleaned.withColumn('minDaughtersEfficiencyScore', min('DaughtersEfficiencyScore').over(w))\\\n",
    "    .where(col('DaughtersEfficiencyScore') == col('minDaughtersEfficiencyScore'))\\\n",
    "    .drop('minDaughtersEfficiencyScore')\n",
    "\n",
    "df_best_bee.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create a tree which the best bee in the cycle (for each cycle)\n",
    "for row in df_best_bee:\n",
    "    #TODO check func maybe change row to DF\n",
    "    create_tree(row).show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
